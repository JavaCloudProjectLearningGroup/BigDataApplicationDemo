# 01 大数据 启蒙

（上半节课）

- 启蒙很重要

- 分治思想

- 单机处理大数据问题

- 集群分布式处理大数据的辩证

## 分治思想

- 需求：

- 我有一万个元素，需要存储，如何存储？

- 如果查找某一个元素，最简单的遍历方式复杂度是多少？

- 如果我期望的复杂度是O(4)
  - 只需要遍历4次，复杂度就是O(4)
  - 如果能确定一个长度是4的链在所有的链中是唯一的
  - 查找X
    -  X.hashCode%2500 == 2

- 分而治之的思想很重要，出现在了很多地方。
- Redis集群
- ElasticSearch
- Hadoop

## 单机处理大数据问题

- 需求：

- 有一个非常大的文本文件，里面有很多很多的行，只有两行一样，它们出现在位置的位置，需要查找到它们。

- 单机，而且可用的内存很少，也就几十兆。

  

- 假设IO速度是500MB每秒

- 1T文件读取一遍需要约30分钟

- 循环遍历需要n次IO时间

- 分治思想可以是时间为2次io

- 计算机而言，IO是最大的瓶颈，程序员需要规避IO的消耗

- 答案：readLine().hashCode % 2000 

- 原理：hashCode()的算法是稳定的，重复行的运算结果是一致的，

  - 而且%2000也是运算稳定的
  - 1T文件散列成2000个小文件（第一次IO）
  - 每个小文件也要读取一遍（第二次IO）

  

- 需求：排序1T的数字列表

- 锻炼方向：技术选型

  - hashcode已经不能用了

    

  - 第一个方法

  - 每个数分配某个范围内（第一次IO）

  - 外部有序，内部无序

  - 每个范围都做一次全排序（第二次IO）

    

  - 另一个方法：外部无序，内部有序，每个小文件都是50M

  - 每个小文件都先做排序

  - 以后再遇到 “外部无序，内部有序” 这个词，要大脑反射出来一个词 “归并排序算法”

    

- 以后就是MapReduce，现在是单机模型

  

- 需求变成分钟和秒级别

- 分析：需要使用更多台机器，减轻单机的IO的时间消耗

- 1T =2000 * 500M

- IO速度500M/s

- 借助网络传输，合并每个%2000 == 0的行，每个 == 1 行，即使每个传输的时间50s，但是可以网卡100M带宽，拉取数据可以并行，拉500M可以只拉5s。甚至1分钟也算很快。前后1~2s（500M / 500M/s），总共1分02秒

  

- 但是还有个环节：分发的过程很久，30分钟读完每个500M文件（读完1T并分割完成2000个500M文件）*5（每个500M文件，同时网卡带宽是500M/s，所以，上传的时间是5秒） ~= 150min

- 移动数据的时间成本很高（需要熟记的概念）

- 名台词：移动计算到数据，而不要移动数据到计算

  - 意思是，先用hashcode运算每个小文件，然后传输运算分发到各台机器中

  

## 集群分布式处理大数据的辩证

- 2000台真的比1台快么
- 如果考虑分发上传文件的时间呢
- 如果考虑每天都有1T数据的产生呢
- 如果增量了1年，最后一天计算数据要花费多少时间呢
- 运用：例如网易云音乐元旦的全年歌单报表，基于分布式集群（大数据技术）

## 结论

- 分而治之
- 并行计算
- 计算向数据移动
- 数据本地化读取
- 以上这些是学习大数据技术时需要关心的重点

（下半节课）

## Hadoop之父Doug Cutting

- Nutch
- Avro
- Lucene
- Hadoop

## Hadoop的时间简史

两篇google论文，被Hadoop之父用java做成了Hadoop项目

Hadoop项目包含

- Common
- HDFS
- Yarn
- MapReduce

CDH(Cloudera's Distribution including Apache Hadoop)

- 企业偏重于Hadoop 2.6.0

Cloudera公司的软件项目结构图

接入层：Sqoop，Kafka，flume

存储层：HDFS，Kudu，HBase，Object Store

统一服务层：Yarn（资源管理）Sentry（安全管理）

处理层，解析层，服务层：spark（批计算），Hive，Pig，MapReduce，SOLR，Flink（流计算）



- 需求：忘记文件存放的地址，如何解决

- 分析：标记，目录管理，记账 + 存储

- 需求：存钱呢，存钱时是立刻记账么？

  - 数据一致性，分布式需要考虑数据一致性
  - 等到存储结束再记账

- 分布式集群中只有一个主机用来管理记账

  

- 问题：分布式文件系统那么多，为什么hadoop项目中还要开发一个hdfs文件系统？

- 原因：为了更好的支持分布式计算



## 存储模型

- 文件线性按字节切割成块（block），具有offset，id
- 文件与文件的block大小可以不一样
- 一个文件出最后一个block，其他block大小一致
- bock的大小依据硬件的I/O特性调整
- block被分散存放再集群的节点中，具有location
- Block具有副本（replication），没有主从概念，副本不能出现在同一个节点
- 副本是满足可靠性和性能的关键
- 文件上传可以指定block大小和副本数，上传后只能修改副本数
- 一次写入多次读取，不支持修改
- 支持追加数据